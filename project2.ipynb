{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup \n",
    "\n",
    "Unzip the data from stas SA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and update the data in the project\n",
    "!./setup.sh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels.api as sm\n",
    "import scipy.stats as stats\n",
    "from scipy.stats import shapiro\n",
    "from scipy.stats import kruskal\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "import numpy as np                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_level_labels = [\n",
    "    \"Grade R/0\",\n",
    "    \"Grade 1/Sub A/Class 1\",\n",
    "    \"Grade 2/Sub B/Class 2\",\n",
    "    \"Grade 3/Standard 1/ABET/AET 1\",\n",
    "    \"Grade 4/Standard 2\",\n",
    "    \"Grade 5/Standard 3/ABET/AET 2\",\n",
    "    \"Grade 6/Standard 4\",\n",
    "    \"Grade 7/Standard 5/ABET/AET 3\",\n",
    "    \"Grade 8/Standard 6/Form 1\",\n",
    "    \"Grade 9/Standard 7/Form 2/ABET/AET 4/NCV Level 1/OCCUPATIONAL CERTIFICATE - NQF LEVEL 1\",\n",
    "    \"Grade 10/Standard 8/Form 3/NCV Level 2/OCCUPATIONAL CERTIFICATE – NQF LEVEL 2\",\n",
    "    \"Grade 11/Standard 9/Form 4/NCV Level 3/OCCUPATIONAL CERTIFICATE – NQF LEVEL 3\",\n",
    "    \"Grade 12/Standard 10/Form 5/National Senior Certificate/Matric/NCV Level 4/OCCUPATIONAL CERTIFICATE – NQF LEVEL 4\",\n",
    "    \"NTC L/N1/NQF 1\",\n",
    "    \"NTC LL/N2/NQF 2\",\n",
    "    \"NTC LLL/N3/NQF 3\",\n",
    "    \"N4/NTC 4/OCCUPATIONAL CERTIFICATE – NQF LEVEL 5\",\n",
    "    \"N5/NTC 5/OCCUPATIONAL CERTIFICATE – NQF LEVEL 5\",\n",
    "    \"N6/NTC 6/OCCUPATIONAL CERTIFICATE – NQF LEVEL 5\",\n",
    "    \"Certificate with Less Than Grade 12/Standard 10\",\n",
    "    \"Diploma with Less Than Grade 12/Standard 10\",\n",
    "    \"Higher/National/Advance Certificate with Grade 12/Std 10/OCCUPATIONAL CERTIFICATE – NQF LEVEL 5\",\n",
    "    \"Diploma with Grade 12/Standard 10/OCCUPATIONAL CERTIFICATE – NQF LEVEL 6\",\n",
    "    \"Higher Diploma/OCCUPATIONAL CERTIFICATE (B-Tech Diploma) – NQF LEVEL 7\",\n",
    "    \"Bachelor’s Degree/OCCUPATIONAL CERTIFICATE – NQF LEVEL 7\",\n",
    "    \"Honours Degree/Postgraduate Diploma/OCCUPATIONAL CERTIFICATE – NQF LEVEL 8\",\n",
    "    \"Post Higher Diploma (M-Tech and Master's Degree) – NQF LEVEL 9\",\n",
    "    \"Doctoral Degrees (D-Tech and PhD) – NQF LEVEL 10\",\n",
    "    \"Other Than Any of the Above\",\n",
    "    \"Do Not Know\",\n",
    "]\n",
    "\n",
    "other_education_labels = {\n",
    "    98: \"No Schooling\",\n",
    "    99: \"Unspecified\"\n",
    "}\n",
    "\n",
    "employment_labels = {\n",
    "    1: \"Employed\",\n",
    "    2: \"Unemployed\",\n",
    "    3: \"Not economically active\",\n",
    "    8: \"Not applicable\"\n",
    "}\n",
    "\n",
    "education_bins = {\n",
    "    0: \"No Formal Education\",\n",
    "    1: \"Basic Education\",\n",
    "    2: \"Intermediate Education\",\n",
    "    3: \"Secondary Education\",\n",
    "    4: \"Vocational Education\",\n",
    "    5: \"Tertiary Education\",\n",
    "}\n",
    "bin_mapping = {\n",
    "    \"No Schooling\": 0,\n",
    "    \"Grade R/0\": 1,\n",
    "    \"Grade 1/Sub A/Class 1\": 1,\n",
    "    \"Grade 2/Sub B/Class 2\": 1,\n",
    "    \"Grade 3/Standard 1/ABET/AET 1\": 1,\n",
    "    \"Grade 4/Standard 2\": 2,\n",
    "    \"Grade 5/Standard 3/ABET/AET 2\": 2,\n",
    "    \"Grade 6/Standard 4\": 2,\n",
    "    \"Grade 7/Standard 5/ABET/AET 3\": 2,\n",
    "    \"Grade 8/Standard 6/Form 1\": 2,\n",
    "    \"Grade 9/Standard 7/Form 2/ABET/AET 4/NCV Level 1/OCCUPATIONAL CERTIFICATE - NQF LEVEL 1\": 3,\n",
    "    \"Grade 10/Standard 8/Form 3/NCV Level 2/OCCUPATIONAL CERTIFICATE – NQF LEVEL 2\": 3,\n",
    "    \"Grade 11/Standard 9/Form 4/NCV Level 3/OCCUPATIONAL CERTIFICATE – NQF LEVEL 3\": 3,\n",
    "    \"Grade 12/Standard 10/Form 5/National Senior Certificate/Matric/NCV Level 4/OCCUPATIONAL CERTIFICATE – NQF LEVEL 4\": 3,\n",
    "    \"NTC L/N1/NQF 1\": 4,\n",
    "    \"NTC LL/N2/NQF 2\": 4,\n",
    "    \"NTC LLL/N3/NQF 3\": 4,\n",
    "    \"N4/NTC 4/OCCUPATIONAL CERTIFICATE – NQF LEVEL 5\": 4,\n",
    "    \"N5/NTC 5/OCCUPATIONAL CERTIFICATE – NQF LEVEL 5\": 4,\n",
    "    \"N6/NTC 6/OCCUPATIONAL CERTIFICATE – NQF LEVEL 5\": 4,\n",
    "    \"Certificate with Less Than Grade 12/Standard 10\": 3,\n",
    "    \"Diploma with Less Than Grade 12/Standard 10\": 3,\n",
    "    \"Higher/National/Advance Certificate with Grade 12/Std 10/OCCUPATIONAL CERTIFICATE – NQF LEVEL 5\": 5,\n",
    "    \"Diploma with Grade 12/Standard 10/OCCUPATIONAL CERTIFICATE – NQF LEVEL 6\": 5,\n",
    "    \"Higher Diploma/OCCUPATIONAL CERTIFICATE (B-Tech Diploma) – NQF LEVEL 7\": 5,\n",
    "    \"Bachelor’s Degree/OCCUPATIONAL CERTIFICATE – NQF LEVEL 7\": 5,\n",
    "    \"Honours Degree/Postgraduate Diploma/OCCUPATIONAL CERTIFICATE – NQF LEVEL 8\": 5,\n",
    "    \"Post Higher Diploma (M-Tech and Master's Degree) – NQF LEVEL 9\": 5,\n",
    "    \"Doctoral Degrees (D-Tech and PhD) – NQF LEVEL 10\": 5,\n",
    "}\n",
    "\n",
    "\n",
    "file_output = \"report/data\"\n",
    "image_output = \"report/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/GHS-2023-PERSON_F1.csv\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "columns_to_convert = ['psu','employ_Status2','lab_amount','lab_sto', 'prov', 'Sex', 'age', 'age_grp1', 'hhc_relationship']\n",
    "df[columns_to_convert] = df[columns_to_convert].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "df[\"education-name\"] = df['education'].map(lambda x: education_level_labels[x] if x < len(education_level_labels) else other_education_labels[x] if x in other_education_labels.keys() else None)\n",
    "\n",
    "sex_mapping = {1: 'Male', 2: 'Female'}\n",
    "df['Sex'] = df['Sex'].map(sex_mapping)\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hypothesis 1: Does the highest level of education affect the employed status of a working person?\n",
    " - **Null Hypothesis (H₀)**: Education level does not significantly affect the likelihood of being employed.\n",
    " - **Alternative Hypothesis (H₁)**: Education level significantly affects the likelihood of being employed.\n",
    "    \n",
    "To test this hypothesis, we performed a chi-square test of independence. Since both education level and income are categorical variables, the chi-square test is appropriate to evaluate whether there is a statistically significant association between these variables. Additionally, a logistic regression model was used to assess the predictive power of education level on income."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean and prepare data\n",
    "income_data = df[(df['employ_Status2'] <= 2) & (df['education'] != 29) & (df['education'] != 99 )]\n",
    "# map the labels of the education name to the the category of the education\n",
    "income_data['education_category'] = income_data['education-name'].map(bin_mapping)\n",
    "income_data = income_data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a contingency table between education and employment status\n",
    "contingency_table = pd.crosstab(income_data['education_category'], income_data['employ_Status2'])\n",
    "contingency_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform chi squared\n",
    "chi2 = stats.chi2_contingency(contingency_table)\n",
    "\n",
    "# save results as latex table\n",
    "with open(f\"{file_output}/hyp_1_chi_2.tex\", \"w\") as f:\n",
    "    res = pd.DataFrame({\n",
    "        r'$\\chi^2$': {\"Value\": r'{:.2f}'.format(chi2.statistic)},\n",
    "        r'$p$': {\"Value\": r'{:.2f}'.format(chi2.pvalue)}\n",
    "    })\n",
    "    f.write(res.to_latex())\n",
    "\n",
    "\n",
    "print(f\"Chi-square statistic: {chi2.statistic:.2f}\")\n",
    "print(f\"P-value: {chi2.pvalue:.4f}\")\n",
    "\n",
    "alpha = 0.05\n",
    "if chi2.pvalue < alpha:\n",
    "    print(\"Reject the null hypothesis (H₀): Education level significantly affects the likelihood being employed.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis (H₀): Education level does not significantly affect the likelihood of being employed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Perform a Logistic regression on the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(income_data.groupby(['education_category'])['employ_Status2'].count())\n",
    "\n",
    "le = LabelEncoder()\n",
    "X = sm.add_constant(income_data['education_category'])  # Add education as the independent X terms\n",
    "y = income_data['employ_Status2'] - 1  # set employment status at the value to be predicted\n",
    "\n",
    "# Fit logistic regression model\n",
    "model = sm.Logit(y, X)\n",
    "result = model.fit()\n",
    "\n",
    "# Summary of the model\n",
    "with open(f\"{file_output}/hyp_1_log_summary.tex\", \"w\") as f:\n",
    "    f.write(result.summary().as_latex())\n",
    "\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate predicted probabilities\n",
    "# predicted_probabilities = result.predict(X)\n",
    "\n",
    "# # Create bins for the Hosmer-Lemeshow test\n",
    "# data = pd.DataFrame({'observed': y, 'predicted': predicted_probabilities})\n",
    "# data['decile'] = pd.qcut(data['predicted'], 10, labels=False)\n",
    "\n",
    "# # Calculate observed and expected values for each decile\n",
    "# hosmer_lemeshow = data.groupby('decile').agg({'observed': 'sum', 'predicted': 'count'}).reset_index()\n",
    "# hosmer_lemeshow['expected'] = hosmer_lemeshow['predicted'] * (hosmer_lemeshow['observed'].sum() / len(y))\n",
    "\n",
    "# # Calculate the Hosmer-Lemeshow statistic\n",
    "# hl_statistic = ((hosmer_lemeshow['observed'] - hosmer_lemeshow['expected'])**2 / hosmer_lemeshow['expected']).sum()\n",
    "\n",
    "# # Degrees of freedom\n",
    "# df = 8  # 10 deciles - 2 parameters (intercept + slope)\n",
    "\n",
    "# # Calculate p-value using chi-squared distribution\n",
    "# p_value = 1 - sm.stats.chisqprob(hl_statistic, df)\n",
    "\n",
    "# print(f\"Hosmer-Lemeshow statistic: {hl_statistic}, p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Prepare the coefficients for plotting\n",
    "coef = result.params\n",
    "coef.plot(kind='bar', color='skyblue')\n",
    "plt.title('Logistic Regression Coefficients')\n",
    "plt.ylabel('Coefficient Value')\n",
    "plt.axhline(0, color='gray', linestyle='--')  # Reference line at 0\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f\"{image_output}/hyp_1_log_coeff.pdf\", format=\"pdf\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data for plotting\n",
    "\n",
    "income_data['predicted_prob'] = result.predict(X)\n",
    "income_data[\"education_category_name\"] = income_data['education_category'].replace(education_bins)\n",
    "\n",
    "sorted_vals = income_data.sort_values(by='education_category', ascending=True)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='education_category_name', y='predicted_prob', data=sorted_vals, ci=None, palette='Set2')\n",
    "plt.title('Predicted Probability of Unemployment by Education Level')\n",
    "plt.xlabel('Education Level')\n",
    "plt.ylabel('Predicted Probability of unemployed status')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{image_output}/hyp_1_log_pred.pdf\", format=\"pdf\")\n",
    "plt.show()\n",
    "\n",
    "# Assuming df contains the 'income' and 'education_level' columns\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Create a count plot\n",
    "sns.countplot(data=sorted_vals, x='education-name', hue='employ_Status2', palette='Set1')\n",
    "\n",
    "# Customize the plot\n",
    "plt.title('Income Class Distribution Across Education Levels')\n",
    "plt.xlabel('Education Level')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=90)  # Rotate x labels for better readability\n",
    "plt.legend(title='Income Class', loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{image_output}/hyp_1_income_dist.pdf\", format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Calculate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y, income_data['predicted_prob'])\n",
    "roc_auc = roc_auc_score(y, income_data['predicted_prob'])\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label='ROC curve (area = {:.2f})'.format(roc_auc))\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hypothesis 2: Does education level affect the salary?\n",
    "\n",
    "- **Null Hypothesis**:\n",
    "- **Alternative Hypothesis**:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cap the outliers at the 1st and 99th percentiles\n",
    "lower_bound = income_data['lab_salary'].quantile(0.001)\n",
    "upper_bound = income_data['lab_salary'].quantile(0.999)\n",
    "\n",
    "# remove the extreme outliers from 0.1% on either side of the data \n",
    "income_data['lab_salary'] = np.where(income_data['lab_salary'] < lower_bound, lower_bound,\n",
    "                                  np.where(income_data['lab_salary'] > upper_bound, upper_bound,\n",
    "                                           income_data['lab_salary']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_data = income_data[(income_data['lab_amount'] == 1)]\n",
    "income_data['lab_salary'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Test_normally_distributed(group1, name):\n",
    "    ks_eval = stats.kstest(group1, 'norm', args=(np.mean(group1), np.std(group1)))\n",
    "    print(f\"Kolmogorov-Smirnov Test for {name}: W={ks_eval[0]}, p-value={ks_eval[1]}\")\n",
    "\n",
    "    with open(f\"{file_output}/hyp_2_norm_dist_{name}.tex\", \"w\") as f:\n",
    "        res = pd.DataFrame({\n",
    "            r\"W\": {\"Value\": ks_eval[0]},\n",
    "            r\"$p$\": {\"Value\": ks_eval[1]}\n",
    "        })\n",
    "        f.write(res.to_latex())\n",
    "\n",
    "    if ks_eval.pvalue <= 0.05:\n",
    "        print(f\"The data is not normally distributed\")\n",
    "    else:\n",
    "        print(\"The data is normally distributed\")\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    stats.probplot(group1, dist=\"norm\", plot=plt)\n",
    "    plt.title(f'Q-Q Plot for {name}')\n",
    "    \n",
    "    # plt.subplot(1, 2, 2)\n",
    "    # sns.histplot(group1, kde=True)\n",
    "    # plt.title(f'Hours Worked by {name} with KDE')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{image_output}/hyp_2_norm_dist_{name}.pdf\", format='pdf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_data = income_data[(income_data['lab_amount'] == 1) & (income_data['lab_salary'] < 88888888)]\n",
    "income_data['education_category'] = income_data['education_category'].astype('category')\n",
    "\n",
    "Test_normally_distributed(income_data[\"lab_salary\"], \"income data\")\n",
    "\n",
    "anova_model = ols('lab_salary ~ C(education_category)', data=income_data).fit()\n",
    "anova_table = sm.stats.anova_lm(anova_model, typ=2)\n",
    "\n",
    "anova_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import levene\n",
    "# Perform Levene's test\n",
    "levene_test = levene(\n",
    "                    *[group['lab_salary'] for name, group in income_data.groupby('education_category', observed=False)]\n",
    "                    ) # Add more groups if necessary\n",
    "\n",
    "with open(f\"{file_output}/hyp_2_levene_test.tex\", \"w\") as f:\n",
    "    res = pd.DataFrame({\n",
    "        r'levene statistic': {\"Value\": r'{:.2f}'.format(levene_test.statistic)},\n",
    "        r'$p$': {\"Value\": r'{:.2f}'.format(levene_test.pvalue)}\n",
    "    })\n",
    "    f.write(res.to_latex())\n",
    "\n",
    "print(\"Levene's Test for Homogeneity of Variances:\")\n",
    "print(f\"Statistic: {levene_test.statistic}, p-value: {levene_test.pvalue}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = [group['lab_salary'].values for name, group in income_data.groupby('education_category', observed=False)]\n",
    "kruskal_statistic, kruskal_p_value = kruskal(*groups)\n",
    "\n",
    "print(kruskal_statistic)\n",
    "kruskal_p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.anova import anova_lm\n",
    "\n",
    "model = sm.OLS.from_formula('lab_salary ~ education_category', data=income_data).fit()\n",
    "welch = anova_lm(model, robust='hc3')\n",
    "\n",
    "with open(f\"{file_output}/hyp_2_welch_res.tex\", \"w\") as f:\n",
    "    f.write(welch.to_latex(index=False, escape=True,float_format=\"%.3f\"))\n",
    "\n",
    "print(f\"Welch's ANOVA statistic: {welch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Perform Tukey's HSD test\n",
    "tukey = pairwise_tukeyhsd(endog=income_data['lab_salary'], groups=income_data['education_category'], alpha=0.05)\n",
    "\n",
    "with open(f\"{file_output}/hyp_2_tukey.tex\", \"w\") as f:\n",
    "    tukey_df = pd.DataFrame(data=tukey._results_table.data[1:], \n",
    "                        columns=tukey._results_table.data[0])\n",
    "    \n",
    "    latex_table = tukey_df.to_latex(float_format=\"%.4f\",escape=True)\n",
    "    f.write(latex_table)\n",
    "# Display the results\n",
    "print(tukey)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hypothesis 3: Does Age affect the salary of a working person?\n",
    "- **Null Hypothesis (H₀)**: Age does not significantly affect salary compensation.\n",
    "- **Alternative Hypothesis (H₁)**: Age significantly affects salary compensation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_data[['age', 'lab_salary', 'education_category']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "corr_stat, p_value = pearsonr(income_data['age'], income_data['lab_salary'])\n",
    "\n",
    "with open(f\"{file_output}/hyp_3_pearson_test.tex\", \"w\") as f:\n",
    "    res = pd.DataFrame({\n",
    "        r'Pearson correlation statistic': {\"Value\": r'{:.2f}'.format(corr_stat)},\n",
    "        r'$p$': {\"Value\": r'{:.2f}'.format(p_value)}\n",
    "    })\n",
    "    f.write(res.to_latex())\n",
    "print(f\"Pearson Correlation: {corr_stat}, p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(income_data[['age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sm.add_constant(X_scaled)  # Add constant for intercept\n",
    "y = income_data['lab_salary']\n",
    "model = sm.OLS(y, X).fit()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "robust_model = model.get_robustcov_results()\n",
    "\n",
    "with open(f\"{file_output}/hyp_3_log_summary.tex\", \"w\") as f:\n",
    "    f.write(result.summary().as_latex())\n",
    "\n",
    "robust_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=income_data, x='age', y='lab_salary', alpha=0.5)\n",
    "sns.regplot(data=income_data, x='age', y='lab_salary', scatter=False, color='orange')\n",
    "plt.title('Scatter Plot of Age vs Salary')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Salary')\n",
    "plt.grid(True)\n",
    "plt.savefig(f\"{image_output}/hyp_3_age_v_salary_scatter.pdf\", format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_bins = [0, 25, 35, 45, 55, 65, 75]\n",
    "age_labels = ['<25', '25-35', '35-45', '45-55', '55-65', '65+']\n",
    "income_data['age_group'] = pd.cut(income_data['age'], bins=age_bins, labels=age_labels)\n",
    "\n",
    "# Box plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.violinplot(data=income_data, x='age_group', y='lab_salary')\n",
    "plt.title('Violin Plot of Salary by Age Group')\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Salary')\n",
    "plt.grid(True)\n",
    "plt.savefig(f'{image_output}/hyp3_salary_by_age_violin.pdf', format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_salary_by_age = income_data.groupby('age_group')['lab_salary'].mean().reset_index()\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=avg_salary_by_age, x='age_group', y='lab_salary', marker='o')\n",
    "plt.title('Average Salary by Age Group')\n",
    "plt.xlabel('Age Group')\n",
    "plt.ylabel('Average Salary')\n",
    "plt.grid(True)\n",
    "plt.savefig(f'{image_output}/hyp_3_average_salary.pdf', format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "band_size = 500\n",
    "cut_off = 20000\n",
    "\n",
    "salary_bins = [i for i in range(0, cut_off + band_size, band_size)]\n",
    "salary_labels = salary_bins[:len(salary_bins)-1]\n",
    "# salary_labels = ['<20K', '20K-40K', '40K-60K', '60K-80K', '80K-100K', '100K+']\n",
    "income_data['salary_group'] = pd.cut(income_data['lab_salary'], bins=salary_bins, labels=salary_labels)\n",
    "\n",
    "\n",
    "# Create a pivot table for heatmap\n",
    "heatmap_data = pd.pivot_table(income_data, values='lab_salary', index='age_group', columns='salary_group', aggfunc='count')\n",
    "\n",
    "# Heatmap\n",
    "plt.figure(figsize=(25, 6))\n",
    "sns.heatmap(heatmap_data, annot=True, cmap='YlGnBu', fmt='g')\n",
    "plt.title('Heatmap of Age Group vs Salary Group')\n",
    "plt.xlabel('Salary Group lower bound')\n",
    "plt.ylabel('Age Group')\n",
    "plt.savefig(f'{image_output}/hyp_3_heat_map.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(income_data, col=\"education_category_name\", col_wrap=3, height=4, sharey=False)\n",
    "g.map(sns.scatterplot, \"age\", \"lab_salary\", alpha=0.5)\n",
    "g.map(sns.regplot, \"age\", \"lab_salary\", scatter=False, color='orange')\n",
    "g.set_titles(template=\"{col_name}\")\n",
    "g.set_axis_labels(\"Age\", \"Salary (rands per month)\")\n",
    "plt.subplots_adjust(top=0.9)\n",
    "g.fig.suptitle('Age vs Salary by Education Level')\n",
    "plt.savefig(f'{image_output}/hyp_3_facet.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hypothesis 4: Gender and equality\n",
    "1. ***Gender and Salary***:\n",
    "    - **Null Hypothesis (H₀)**: Gender does not significantly affect salary.\n",
    "    - **Alternative Hypothesis (H₁)**: Gender significantly affects salary.\n",
    "\n",
    "2. ***Gender and Education Level***:\n",
    "    - **Null Hypothesis (H₀)**: Gender does not significantly affect education level.\n",
    "    - **Alternative Hypothesis (H₁)**: Gender significantly affects education level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_salary = income_data[income_data['Sex'] == 'Male']['lab_salary']\n",
    "female_salary = income_data[income_data['Sex'] == 'Female']['lab_salary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_salary.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_salary.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "# Separate the data into two groups based on gender\n",
    "male_salary = income_data[income_data['Sex'] == 'Male']['lab_salary']\n",
    "female_salary = income_data[income_data['Sex'] == 'Female']['lab_salary']\n",
    "\n",
    "Test_normally_distributed(male_salary, \"male-salary\")\n",
    "Test_normally_distributed(male_salary, \"female-salary\")\n",
    "\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "stat, p_value = mannwhitneyu(male_salary, female_salary)\n",
    "\n",
    "with open(f\"{file_output}/hyp_4_t_test.tex\", \"w\") as f:\n",
    "    res = pd.DataFrame({\n",
    "        r't\\\\-test statistic': {\"Value\": r'{:.2f}'.format(stat)},\n",
    "        r'$p$': {\"Value\": r'{:.2f}'.format(p_value)}\n",
    "    })\n",
    "    f.write(res.to_latex())\n",
    "\n",
    "print(f\"Whiteney u statistic: {stat}, p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.violinplot(data=income_data, x='Sex', y='lab_salary')\n",
    "plt.title('Box Plot of Salary by Gender')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('Salary')\n",
    "plt.grid(True)\n",
    "plt.savefig(f\"{image_output}/hyp_4_violin.pdf\", format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Create a contingency table\n",
    "contingency_table = pd.crosstab(income_data['Sex'], income_data['education_category'])\n",
    "\n",
    "# Perform the Chi-Squared test\n",
    "chi2_stat, p_value, dof, expected = chi2_contingency(contingency_table)\n",
    "\n",
    "with open(f\"{file_output}/hyp_4_t_test.tex\", \"w\") as f:\n",
    "    res = pd.DataFrame({\n",
    "        r'$\\chi^2$': {\"Value\": r'{:.2f}'.format(chi2_stat)},\n",
    "        r'$p$': {\"Value\": r'{:.2f}'.format(p_value)}\n",
    "    })\n",
    "    f.write(res.to_latex())\n",
    "print(f\"Chi-Squared statistic: {chi2_stat}, p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "education_gender_count = pd.crosstab(income_data['education_category'], income_data['Sex'])\n",
    "\n",
    "# Plot the bar chart\n",
    "education_gender_count.plot(kind='bar', figsize=(12, 6))\n",
    "plt.title('Counts of Gender Across Education Levels')\n",
    "plt.xlabel('Education Level')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Gender')\n",
    "plt.savefig(f'{image_output}/hyp_4_bar_plot.pdf', format=\"pdf\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.yscale('log')\n",
    "plt.subplot()\n",
    "sns.histplot(male_salary, bins=30, kde=True)\n",
    "plt.title('Histogram of Logged Salary')\n",
    "plt.xlabel('Logged Salary')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot()\n",
    "sns.histplot(female_salary, bins=30, kde=True)\n",
    "plt.title('Histogram of Logged Salary')\n",
    "plt.xlabel('Logged Salary')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.savefig(f\"{image_output}/hyp_4_kde_plot.pdf\", format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Hypothesis 5: Does ethnicity affect the salary of a working person? \n",
    "- **Null Hypothesis (H₀)**: There is no significant difference in salary based on race, controlling for education level.\n",
    "- **Alternative Hypothesis (H₁)**: There is a significant difference in salary based on race, controlling for education level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = [group['lab_salary'].values for name, group in income_data.groupby('Population')]\n",
    "\n",
    "for g in groups:\n",
    "    Test_normally_distributed(g, f\"population\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kruskal\n",
    "import scikit_posthocs as sp\n",
    "\n",
    "H_statistic, p_value = kruskal(*groups)\n",
    "\n",
    "with open(f\"{file_output}/hyp_5_anova.tex\", \"w\") as f:\n",
    "    res = pd.DataFrame({\n",
    "        r'Anova statistic': {\"Value\": r'{:.2f}'.format(H_statistic)},\n",
    "        r'$p$': {\"Value\": r'{:.2f}'.format(p_value)}\n",
    "    })\n",
    "    f.write(res.to_latex())\n",
    "\n",
    "print(f\"Kruskal-Wallis H statistic: {H_statistic}, p-value: {p_value}\")\n",
    "\n",
    "\n",
    "dunn_results = sp.posthoc_dunn(income_data, val_col='lab_salary', group_col='Population', p_adjust='bonferroni')\n",
    "print(dunn_results)\n",
    "\n",
    "# If you find significant results, visualize the differences\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.violinplot(x='Population', y='lab_salary', data=income_data)\n",
    "plt.title('Salary Distribution by Race')\n",
    "plt.ylabel('Salary')\n",
    "plt.xlabel('Race')\n",
    "plt.grid(True)\n",
    "plt.savefig(f'{image_output}/hyp_5_violin_plot.pdf', format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model: Salary ~ Race + Education Level\n",
    "model = ols('lab_salary ~ C(Population) + C(education_category)', data=income_data).fit()\n",
    "anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "\n",
    "with open(f\"{file_output}/hyp_5_anova_lm.tex\", \"w\") as f:\n",
    "    f.write(anova_table.to_latex(float_format=\"%.3f\", escape=True))\n",
    "\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "# Load your dataset\n",
    "\n",
    "# Select relevant features for clustering\n",
    "features = ['age', 'lab_salary']\n",
    "X = income_data[features]\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# pca = PCA(n_components=2)  # Reduce to 2 dimensions for visualization\n",
    "# X_scaled = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Determine the optimal number of clusters using the elbow method\n",
    "inertia = []\n",
    "sil_score = []\n",
    "for i in range(2, 11):\n",
    "    kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)\n",
    "    kmeans.fit(X_scaled)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "    labels = kmeans.labels_\n",
    "    sil_score.append(silhouette_score(X_scaled, labels))\n",
    "\n",
    "# Plot the elbow method\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(2, 11), inertia, marker='o')\n",
    "plt.title('Elbow Method')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Inertia')\n",
    "plt.savefig(f\"{image_output}/clustering_k_means_inertia.pdf\", format=\"pdf\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(2, 11), sil_score, marker='o')\n",
    "plt.title('Silhouette score')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Silhouette score')\n",
    "plt.savefig(f\"{image_output}/clustering_k_means_sil.pdf\", format=\"pdf\")\n",
    "plt.show()\n",
    "\n",
    "# Choose the optimal number of clusters, e.g., 3\n",
    "optimal_clusters = 4\n",
    "kmeans = KMeans(n_clusters=optimal_clusters, random_state=42)\n",
    "income_data['Cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "sns.scatterplot(data=income_data, x='age', y='lab_salary', hue='Cluster', palette='viridis')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Salary')\n",
    "plt.title('K-Means Clustering of age and salary')\n",
    "plt.savefig(f\"{image_output}/clustering_k_means.pdf\", format=\"pdf\")\n",
    "# plt.colorbar(label='Cluster')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "import gower\n",
    "\n",
    "cluster_data = income_data[income_data[\"soc_grant\"] < 3]\n",
    "\n",
    "cluster_labels = ['age_group','education_category', 'Population', 'employ_Status2', \"Sex\", \"soc_grant\"]\n",
    "cluster_data['Population'] = cluster_data['Population'].astype('str')\n",
    "cluster_data['education_category'] = cluster_data['education_category'].astype('str')\n",
    "cluster_data['employ_Status2'] = cluster_data['employ_Status2'].astype('str')\n",
    "cluster_data['age_group'] = cluster_data['age_group'].astype('str')\n",
    "cluster_data['soc_grant'] = cluster_data['soc_grant'].astype('str')\n",
    "# print(cluster_data)\n",
    "\n",
    "# from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "gower_distance = gower.gower_matrix(cluster_data[cluster_labels])\n",
    "\n",
    "linked = linkage(gower_distance, method='average')\n",
    "dendrogram(linked, no_labels=True)\n",
    "plt.savefig(f'{image_output}/clustering_dendrogram.pdf', format=\"pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "silhouette_scores = []\n",
    "for i in range(2, 11):\n",
    "    clusters = fcluster(linked, i, criterion='maxclust')\n",
    "    score = silhouette_score(gower_distance, clusters, metric='precomputed')  # Using precomputed Gower distance\n",
    "    silhouette_scores.append(score)\n",
    "\n",
    "# Plot silhouette scores\n",
    "plt.plot(range(2, 11), silhouette_scores, marker='o')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.title('Silhouette Score for Optimal Number of Clusters')\n",
    "plt.savefig(f'{image_output}/clustering_dendro_sil.pdf', format=\"pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data[\"hierachy_clusters\"] = fcluster(linked, 4, criterion='maxclust')\n",
    "\n",
    "cluster_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
